---
title: "Netflix - Average Browsing Time Experiment"
output: github_document
---


```{r}
library(plot3D)
library(gplots)

# Phase 1 - Factor Screening

# Function to create blues
blue_palette <- colorRampPalette(c(rgb(247,251,255,maxColorValue = 255), 
                                   rgb(8,48,107,maxColorValue = 255)))

# Function for converting from natural units to coded units
convert.N.to.C <- function(U,UH,UL){
  x <- (U - (UH+UL)/2) / ((UH-UL)/2)
  return(x)
}

# Function for converting from coded units to natural units
convert.C.to.N <- function(x,UH,UL){
  U <- x*((UH-UL)/2) + (UH+UL)/2
  return(U)
}
```

```{r}
setwd(dir = "/Users/shermeenvelani/Documents/Projects/Netflix - Experimental Design/")
Fact.Scr <- read.csv(file = "Phase1_Results_2^3.csv", header = T)

# Creating a data frame with the response variable and 3 factors in coded units.
# This data frame will be fed to the model
ph1 <- data.frame(y=Fact.Scr$Browse.Time,
                  TS = convert.N.to.C(Fact.Scr$Tile.Size,0.3,0.1),
                  PS = convert.N.to.C(Fact.Scr$Prev.Size,0.5,0.3),
                  PL = convert.N.to.C(Fact.Scr$Prev.Length,90,30))


# Linear regression

model <- lm(y~(TS+PS+PL)^3, data = ph1)
summary(model)
```

At the 5% significance level, we can see that Tile Size is not significant and
therefore can be removed. We are now left with 2 factors i.e. Preview Size
and Preview Length

The graphs below show the results obtained above


Plots

```{r}
par(mfrow=c(2,3))
plotmeans(formula = y~TS, ylab = "Average Browsing Time", xlab = "Tile.Size", 
          data = ph1, xaxt = "n", pch = 16,ylim = c(16,21))
axis(side = 1, at = c(1,2), labels = c("0.1", "0.3"))
plotmeans(formula = y~PS, ylab = "Average Browsing Time", xlab = "Prev.Size", 
          data = ph1, xaxt = "n", pch = 16,ylim = c(16,21))
axis(side = 1, at = c(1,2), labels = c("0.3", "0.5"))
```
```{r}
par(mfrow=c(2,3))
plotmeans(formula = y~PL, ylab = "Average Browsing Time", xlab = "Prev.Length", 
          data = ph1, xaxt = "n", pch = 16,ylim = c(16,21))
axis(side = 1, at = c(1,2), labels = c("30", "90"))
```
```{r}


## Phase 2
## We have 2 factors now - Preview Size and Preview Length

netflix.ph2 <- read.csv("Phase2_2^2+cp.csv", header = TRUE)

## The factors and their low/center/high levels are as follows:
## Preview Length: 30  vs 60  vs 90
## Preview Size:   0.3 vs 0.4 vs 0.5


## Determine whethere we're close to the optimum to begin with
## (i.e, check whether the pure quadratic effect is significant)
ph2 <- data.frame(y = netflix.ph2$Browse.Time,
                  x1 = convert.N.to.C(U = netflix.ph2$Prev.Length, UH = 90, 
                                      UL = 30),
                  x2 = convert.N.to.C(U = netflix.ph2$Prev.Size, UH = 0.5, 
                                      UL = 0.3))
ph2$xPQ <- (ph2$x1^2 + ph2$x2^2)/2

## Check the average browsing time in each condition:
aggregate(ph2$y, by = list(x1 = ph2$x1, x2 = ph2$x2), FUN = mean)


## The difference in average browsing time in factorial conditions vs. the 
## center point condition
mean(ph2$y[ph2$xPQ != 0]) - mean(ph2$y[ph2$xPQ == 0])


## Check to see if that's significant
m <- lm(y~x1+x2+x1*x2+xPQ, data = ph2)
summary(m)
```
We test the null hypothesis for coefficient of curvature being zero. 

Since the pvalue is 0.97 we fail to reject the null hypothesis and therefore
are not in the presence of quadratic curvature. To find the quadratic curvature,
we need to use the method of steepest descent
